{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For matrix calculation\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Random number generator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training_data.npy numpy file\n",
    "# This file includes our data which we collected before. Every folder has own training_data.npy\n",
    "# PATH is data folder we want to train\n",
    "# Only change the PATH\n",
    "PATH='../deep_learning/data/001/'\n",
    "data = np.load(PATH+'training_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if we correctly load the file\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another checking\n",
    "data[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize any image in the data set\n",
    "from PIL import Image\n",
    "# It should be lower than the total number of images which shown in the upper cell\n",
    "IMAGE = 30\n",
    "image = Image.open(PATH+data[IMAGE][0])\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping the image from the top is useful for training as it will remove irrelevant data\n",
    "image = np.asarray(image.resize((320, 180), Image.ANTIALIAS))\n",
    "plt.figure(figsize=(15,5))\n",
    "CROP = 100\n",
    "plt.imshow(image[CROP:,:,:]) #Cropped image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assign the image paths and the corresponding labels to two separate same size arrays\n",
    "images = list(img[0] for img in data[1:])\n",
    "labels = list(float(img[2]) for img in data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of angles in our data\n",
    "# Uneven distribution of the training leads to failure of training\n",
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentasyon işlemi\n",
    "\n",
    " Augmentasyon işlemini tamamladıktan sonra **model_trainer.py** dosyasında ilgili yere aşağıdaki kod bloğunu yapıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to correct the angle distribution in the data set, \n",
    "# we try to re-add the number of angle records to the list.\n",
    "# In other words augmentation\n",
    "nitem = len(images)\n",
    "for i in range(nitem):\n",
    "    if labels[i] > 0.05:\n",
    "        for j in range(7):\n",
    "            images.append(images[i])\n",
    "            labels.append(labels[i])    \n",
    "    if labels[i] < -0.07:\n",
    "        for j in range(2):\n",
    "            images.append(images[i])\n",
    "            labels.append(labels[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İlk histgorama göre daga dengeli sayılabilecek bir dağılıma ulaştık\n",
    "# En doğru çözüm değil ama pratik işe yarar bir alternatif\n",
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Veri setimiz ile ilgili ayarlamalar\n",
    "# Veri seti küme büyüklüğü batch size\n",
    "# Verisetinin ne kadarı eğitim ne kadarı test için kullanılacak\n",
    "# Eğitim %80 , Test %20 \n",
    "bsize = 8\n",
    "dlen = len(labels)\n",
    "splitpoint = int(0.8*dlen)\n",
    "reindex = list(range(len(labels)))\n",
    "# Eğtim verisini karıştıryoruz\n",
    "random.seed(1234)\n",
    "random.shuffle(reindex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resim üzerinde Rastgele parlaklık değişimi uygulayan bir fonksiyon\n",
    "# Augmentation function (taken from github)\n",
    "def augment_brightness(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_BGR2HSV) \n",
    "    image1 = np.array(image1, dtype = np.float64)\n",
    "    random_bright = .5+np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1[:,:,2][image1[:,:,2]>255]  = 255\n",
    "    image1 = np.array(image1, dtype = np.uint8)\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# ismi verilen resmi okuyup \n",
    "# rastgele olarak %50 sine parlaklık değişimi uygulayan fonksiyonu uygulayıp\n",
    "# resim matrisini dönem bir fonksiyon\n",
    "\n",
    "def get_matrix(fname):\n",
    "    img = cv2.imread(PATH+fname)\n",
    "    img = cv2.resize(img, (320,180))\n",
    "    if random.randint(0,1) == 1 :\n",
    "        img = augment_brightness(img)        \n",
    "    return img[100:,:,:] # Return the cropped image, (320,80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bütün veriyi hafızaya almamız mümkün değil\n",
    "# Ek olarak bazen çeşitli değişimler - Augmentation - uygulamakda istiyebiliriz\n",
    "# python generator ile gerektiğinde veri okunur düzenlenir ve eğitim veya test için \n",
    "# sisteme verilir\n",
    "# alttaki fonksiyonlar bu işi yapar\n",
    "\n",
    "# Generate data for training\n",
    "def generate_data():\n",
    "    i = 0\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for j in range(i,i+bsize):  \n",
    "            ix = reindex[j]\n",
    "            img = get_matrix(images[ix])\n",
    "            lbl = np.array([labels[ix]])\n",
    "            flip = random.randint(0,1)\n",
    "            if flip == 1:\n",
    "                img = cv2.flip(img,1)\n",
    "                lbl = lbl*-1.0\n",
    "            x.append(img)\n",
    "            y.append(lbl)\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)       \n",
    "        yield (x,y)    \n",
    "        i +=bsize\n",
    "        if i+bsize > splitpoint:\n",
    "            i = 0\n",
    "            \n",
    "# Generate data for validation                  \n",
    "def generate_data_val():\n",
    "    i = splitpoint\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for j in range(i,i+bsize): \n",
    "            ix = reindex[j]\n",
    "            x.append(get_matrix(images[ix]))\n",
    "            y.append(np.array([labels[ix]]))\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)       \n",
    "        yield (x,y)    \n",
    "        i +=bsize\n",
    "        if i+bsize > dlen:\n",
    "            i = splitpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras için gerekenler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, Cropping2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model based on NVIDIA's End to End Learning for Self-Driving Cars model\n",
    "# Sıralı bir keras modeli tanılıyoruz\n",
    "model = Sequential()\n",
    "# Normalization\n",
    "# 0 - 255 arası değerler -1 ila 1 arasına çekiliyor\n",
    "model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(80, 320, 3)))\n",
    "# Evrişim katmanı (5, 5) lik 24 tane 2 şer piksel kayarak\n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "# Ağın çıkışı burda vectöre çevriliyor\n",
    "model.add(Flatten())\n",
    "# Yapay Sinir ağı kısmı\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "# Ağın çıkışı Açı \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanımladığımız ağın yapsı\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Açı değerlerinide -0.3 ila 0.3 aralığından -1 ila 1 aralığına çekebilmek için 3 ile çarpıyoruz\n",
    "labels = 3*np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim esnasında test hata değeri en düşük değeri kaydeden bir fonksiyon\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim fonksiyonu \n",
    "hs = model.fit_generator(generate_data(),steps_per_epoch=int(splitpoint/ bsize),\n",
    "                    validation_data=generate_data_val(), \n",
    "                    validation_steps=(dlen-splitpoint)/bsize, epochs=10,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
